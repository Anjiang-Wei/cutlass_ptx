
/*
  Generated by gemm_operation.py - Do not edit.
*/

///////////////////////////////////////////////////////////////////////////////////////////////////

#include "cutlass/cutlass.h"
#include "cutlass/library/library.h"
#include "cutlass/library/manifest.h"
#include "library_internal.h"
#include "gemm_operation.h"
#include "gemm_operation_3x.hpp"
#include "grouped_gemm_operation_3x.hpp"
#include "sparse_gemm_operation_3x.hpp"
#include "block_scaled_gemm_operation_3x.hpp"
#include "blockwise_gemm_operation_3x.hpp"
#include "cutlass/arch/wmma.h"
#include "cutlass/numeric_types.h"
#include "cutlass/arch/arch.h"
#include "cutlass/arch/mma.h"
#include "cutlass/layout/matrix.h"
#include "cutlass/gemm/device/gemm.h"
#include "cutlass/gemm/kernel/gemm_grouped.h"
#include "cutlass/gemm/kernel/default_gemm_grouped.h"
#include "cutlass/gemm/device/gemm_grouped.h"

///////////////////////////////////////////////////////////////////////////////////////////////////


// Gemm operator cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice
using cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice_base =
  typename cutlass::gemm::kernel::DefaultGemmGrouped<
    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 4,
    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 4,
    float, cutlass::layout::ColumnMajor,
    float,
    cutlass::arch::OpClassTensorOp,
    cutlass::arch::Sm80,
    cutlass::gemm::GemmShape<64, 256, 32>,
    cutlass::gemm::GemmShape<64, 64, 32>,
    cutlass::gemm::GemmShape<16, 8, 16>,
    cutlass::epilogue::thread::LinearCombination<
      float,
      4,
      float,
      float
    >,
    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
    4,
    cutlass::gemm::kernel::GroupScheduleMode::kDeviceOnly,
    cutlass::arch::OpMultiplyAdd
>::GemmKernel;

// Define named type
struct cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice :
  public cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice_base { };


///////////////////////////////////////////////////////////////////////////////////////////////////

namespace cutlass {
namespace library {

///////////////////////////////////////////////////////////////////////////////////////////////////

void initialize_cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice(Manifest &manifest) {



  manifest.append(new GemmGroupedOperation<
    cutlass::gemm::device::GemmGrouped<cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice>
  >("cutlass_tensorop_s16816gemm_grouped_bf16_64x256_32x4_tt_align4_scheduleDevice"));



}

///////////////////////////////////////////////////////////////////////////////////////////////////

} // namespace library
} // namespace cutlass

///////////////////////////////////////////////////////////////////////////////////////////////////

